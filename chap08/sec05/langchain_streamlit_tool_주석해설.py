import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage

from langchain_core.tools import tool
from datetime import datetime
import pytz

# openai_api_keyê°€ì ¸ì˜¤ê¸°
from openai import OpenAI  # ì£¼ì„ì²˜ë¦¬
from dotenv import load_dotenv
import os
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
# openai_api_keyê°€ì ¸ì˜¤ê¸°

# ëª¨ë¸ ì´ˆê¸°í™”
# - LangChainìš© OpenAI ì±— ëª¨ë¸ ë˜í¼
# - ì—¬ê¸°ì„œëŠ” ê²½ëŸ‰ ë©€í‹°ëª¨ë‹¬ ê³„ì—´ 'gpt-4o-mini'ë¥¼ ì‚¬ìš©
llm = ChatOpenAI(model="gpt-4o-mini")

# ë„êµ¬ í•¨ìˆ˜ ì •ì˜
@tool
def get_current_time(timezone: str, location: str) -> str:
    """í˜„ì¬ ì‹œê°ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜."""
    # - LangChainì˜ @tool ë°ì½”ë ˆì´í„°ë¡œ ë„êµ¬(íˆ´)ë¡œ ë…¸ì¶œ
    # - LLMì´ í•¨ìˆ˜ í˜¸ì¶œ(íˆ´ ì½œ)ì„ ê²°ì •í•˜ë©´, ì´ í•¨ìˆ˜ê°€ ì‹¤í–‰ë¨
    try:
        # ì…ë ¥ë°›ì€ íƒ€ì„ì¡´ ë¬¸ìì—´ì„ pytz ê°ì²´ë¡œ ë³€í™˜
        tz = pytz.timezone(timezone)
        # í•´ë‹¹ íƒ€ì„ì¡´ì˜ í˜„ì¬ ì‹œê°ì„ 'YYYY-MM-DD HH:MM:SS' ë¬¸ìì—´ë¡œ í¬ë§·
        now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
        # ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ ê²°ê³¼ ë¬¸ìì—´ êµ¬ì„±
        result = f'{timezone} ({location}) í˜„ì¬ì‹œê° {now}'
        print(result)  # ì„œë²„ ë¡œê·¸ì— ì¶œë ¥(ë””ë²„ê¹…/ëª¨ë‹ˆí„°ë§ ìš©)
        return result   # LangChainì´ ToolMessageë¡œ ê°ìŒ€ ìˆ˜ ìˆëŠ” ë¬¸ìì—´ ë°˜í™˜
    except pytz.UnknownTimeZoneError:
        # ìœ íš¨í•˜ì§€ ì•Šì€ íƒ€ì„ì¡´ì¼ ë•Œ ì˜ˆì™¸ ì²˜ë¦¬
        return f"ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì„ì¡´: {timezone}"

# ë„êµ¬ ë°”ì¸ë”©
tools = [get_current_time]                  # ì‚¬ìš©í•  ë„êµ¬ ëª©ë¡
tool_dict = {"get_current_time": get_current_time}  # ì´ë¦„â†’ì‹¤ì œ í•¨ìˆ˜ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬

# LLMì— ë„êµ¬ ì‚¬ìš© ëŠ¥ë ¥ ë°”ì¸ë”©
# - ì´ ê°ì²´ë¡œ stream()/invoke() ë“±ì„ í˜¸ì¶œí•˜ë©´ ëª¨ë¸ì´ í•„ìš”ì‹œ tool_callsë¥¼ ìƒì„±
llm_with_tools = llm.bind_tools(tools)


# ì‚¬ìš©ìì˜ ë©”ì‹œì§€ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜
def get_ai_response(messages):
    # â‘  ë„êµ¬ê°€ ë°”ì¸ë”©ëœ LLMìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
    # - messages: System/Human/AI/Tool ë©”ì‹œì§€ì˜ ë¦¬ìŠ¤íŠ¸(ëŒ€í™” íˆìŠ¤í† ë¦¬)
    # - stream()ì€ í† í°/ì²­í¬ ë‹¨ìœ„ë¡œ ìƒì„± ê²°ê³¼ë¥¼ ìˆœì°¨ ë°˜í™˜í•˜ëŠ” ì œë„ˆë ˆì´í„°
    response = llm_with_tools.stream(messages) # â‘  llm.stream()ì„ llm_with_tools.stream()ë¡œ ë³€ê²½
    
    gathered = None # â‘¡ ì „ì²´ ìŠ¤íŠ¸ë¦¼ì„ ëˆ„ì í•˜ì—¬ ìµœì¢… ì²­í¬(ë©”íƒ€ í¬í•¨)ë¥¼ ë³´ê´€í•  ë³€ìˆ˜
    for chunk in response:
        # ìŠ¤íŠ¸ë¦¬ë° UIë¥¼ ìœ„í•´ ìƒì„±ë˜ëŠ” ê° ì²­í¬ë¥¼ ì¦‰ì‹œ ë°–ìœ¼ë¡œ ì „ë‹¬(yield)
        yield chunk
        
        if gathered is None: #  â‘¢ ì²« ë²ˆì§¸ ì²­í¬ë©´ ëˆ„ì  ì‹œì‘
            gathered = chunk
        else:
            # ì´í›„ ì²­í¬ë“¤ì€ += ë¡œ ë³‘í•©( LangChain ë©”ì‹œì§€ ì²­í¬ ê°ì²´ ë³‘í•© ì—°ì‚° ì§€ì› ê°€ì • )
            gathered += chunk
 
    # ìŠ¤íŠ¸ë¦¬ë°ì´ ëë‚œ ì‹œì ì—ì„œ, ëª¨ë¸ì´ íˆ´ í˜¸ì¶œì„ ìš”ì²­í–ˆëŠ”ì§€ í™•ì¸
    if gathered.tool_calls:
        # ë°©ê¸ˆê¹Œì§€ì˜ ëª¨ë¸ ì¶œë ¥(íˆ´ ì½œ ë©”íƒ€ í¬í•¨)ì„ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        st.session_state.messages.append(gathered)
        
        # tool_callsì— í¬í•¨ëœ ê° íˆ´ í˜¸ì¶œì„ ì‹¤ì œë¡œ ì‹¤í–‰
        for tool_call in gathered.tool_calls:
            # ëª¨ë¸ì´ ì§€ì •í•œ nameì„ í‚¤ë¡œ ì‹¤ì œ íŒŒì´ì¬ í•¨ìˆ˜ ì„ íƒ
            selected_tool = tool_dict[tool_call['name']]
            # LangChain Tool.invoke(...)ë¡œ í˜¸ì¶œ ì¸ì ì „ë‹¬ ë° ì‹¤í–‰
            # - tool_call ì•ˆì— name/args/id ë“±ì˜ ì •ë³´ê°€ ë“¤ì–´ìˆë‹¤ê³  ê°€ì •
            tool_msg = selected_tool.invoke(tool_call) 
            print(tool_msg, type(tool_msg))  # ë””ë²„ê¹… ì¶œë ¥
            # íˆ´ ì‹¤í–‰ ê²°ê³¼ë¥¼ ToolMessageë¡œ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€(ìŠ¤íŠ¸ë¦¼ë¦¿ í‘œì‹œìš©)
            st.session_state.messages.append(tool_msg)
           
        # íˆ´ ì‹¤í–‰ ê²°ê³¼ê¹Œì§€ íˆìŠ¤í† ë¦¬ì— ë°˜ì˜í–ˆìœ¼ë‹ˆ,
        # ë‹¤ìŒ í„´(í›„ì† ì‘ë‹µ)ì„ ì–»ê¸° ìœ„í•´ ì¬ê·€ì ìœ¼ë¡œ ë‹¤ì‹œ LLM í˜¸ì¶œ (ReAct ë£¨í”„ íŒ¨í„´)
        for chunk in get_ai_response(st.session_state.messages):
            yield chunk


# Streamlit ì•±
st.title("ğŸ’¬ GPT-4o Langchain Chat")  # ì•± íƒ€ì´í‹€

# ìŠ¤íŠ¸ë¦¼ë¦¿ session_stateì— ë©”ì‹œì§€ ì €ì¥
# - ì²« ë°©ë¬¸ ì‹œ ì´ˆê¸° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ê°„ë‹¨í•œ AI ì¸ì‚¬ë§ì„ ì„¸íŒ…
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë•ê¸° ìœ„í•´ ìµœì„ ì„ ë‹¤í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë´‡ì´ë‹¤. "),  # ì—­í•  ê·œì •
        AIMessage("How can I help you?")  # ì²« ì•ˆë‚´ ë©”ì‹œì§€
    ]

# ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ì— ë©”ì‹œì§€ ì¶œë ¥
# - ì„¸ì…˜ì— ìŒ“ì¸ ëŒ€í™”(ì‹œìŠ¤/ìœ ì €/AI/íˆ´)ë¥¼ ê°ê° ë‹¤ë¥¸ ë§í’ì„ ìœ¼ë¡œ í‘œì‹œ
for msg in st.session_state.messages:
    if msg.content:
        if isinstance(msg, SystemMessage):
            st.chat_message("system").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)
        elif isinstance(msg, ToolMessage):
            st.chat_message("tool").write(msg.content)


# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# - í•˜ë‹¨ ì…ë ¥ì°½ì—ì„œ í”„ë¡¬í”„íŠ¸ê°€ ë“¤ì–´ì˜¤ë©´ ì¦‰ì‹œ í•œ í„´ ëŒ€í™”ë¥¼ ì§„í–‰
if prompt := st.chat_input():
    st.chat_message("user").write(prompt)                      # ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ ì¶œë ¥
    st.session_state.messages.append(HumanMessage(prompt))     # ì‚¬ìš©ì ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì €ì¥

    # LLM ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì œë„ˆë ˆì´í„° íšë“
    response = get_ai_response(st.session_state["messages"])
    
    # ìŠ¤íŠ¸ë¦¬ë°ëœ ì²­í¬ë¥¼ ë§í’ì„ ì— ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì¶œ
    # - write_streamì€ ì œë„ˆë ˆì´í„°ë¥¼ ë°›ì•„ ìˆœì°¨ì ìœ¼ë¡œ ì¶œë ¥í•˜ê³ , ìµœì¢… í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
    result = st.chat_message("assistant").write_stream(response) # AI ë©”ì‹œì§€ ì¶œë ¥
    # ìµœì¢… ê²°ê³¼ í…ìŠ¤íŠ¸ë¥¼ AIMessageë¡œ íˆìŠ¤í† ë¦¬ì— ì €ì¥(ë‹¤ìŒ í„´ ë¬¸ë§¥ ìœ ì§€)
    st.session_state["messages"].append(AIMessage(result)) # AI ë©”ì‹œì§€ ì €ì¥


""" 
ë™ì‘ íë¦„ í•µì‹¬ ìš”ì•½

ì„¸ì…˜ ì´ˆê¸°í™”: SystemMessageë¡œ ì—­í• ì„ ì •í•˜ê³ , ê°„ë‹¨ ì¸ì‚¬ AIMessageë¥¼ ì´ˆê¸° íˆìŠ¤í† ë¦¬ì— ì¶”ê°€í•©ë‹ˆë‹¤.

ì…ë ¥ â†’ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ: ì‚¬ìš©ìê°€ ì…ë ¥í•˜ë©´ get_ai_response()ë¡œ LLMì„ ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œí•˜ì—¬ í† í° ë‹¨ìœ„ë¡œ í™”ë©´ì— ì¶œë ¥í•©ë‹ˆë‹¤.

íˆ´ í˜¸ì¶œ(ì˜µì…˜): ëª¨ë¸ì´ tool_callsë¥¼ ìƒì„±í•œ ê²½ìš°, í•´ë‹¹ ë„êµ¬(ì—¬ê¸°ì„œëŠ” get_current_time)ë¥¼ ì‹¤ì œë¡œ ì‹¤í–‰í•˜ê³ , ë„êµ¬ ê²°ê³¼ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€í•œ ë’¤ ì¬ê·€ í˜¸ì¶œë¡œ í›„ì† ë‹µë³€ì„ ì´ì–´ê°‘ë‹ˆë‹¤(ì¼ì¢…ì˜ ReAct íŒ¨í„´).

íˆìŠ¤í† ë¦¬ ê´€ë¦¬: ëª¨ë“  í„´ì˜ System/Human/AI/Tool ë©”ì‹œì§€ë¥¼ st.session_state["messages"]ì— ìŒ“ì•„ ëŒ€í™” ë§¥ë½ ìœ ì§€ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.

ì‹¤ë¬´ íŒ(ì„ íƒ)

í™˜ê²½ë³€ìˆ˜ ë¡œë”©: .envì— OPENAI_API_KEYë¥¼ ë„£ê³  load_dotenv()ë¡œ ë¡œë”©í–ˆìœ¼ë‹ˆ, Streamlit ì‹¤í–‰ ì „ í™˜ê²½ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.

íˆ´ ì¸ì êµ¬ì¡°: tool_callì˜ êµ¬ì¡°ëŠ” LangChain/SDK ë²„ì „ì— ë”°ë¼ {"name": ..., "args": {...}} í˜¹ì€ ToolCall ê°ì²´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì½”ë“œëŠ” selected_tool.invoke(tool_call)ì„ ê°€ì •í•˜ë¯€ë¡œ, ë²„ì „ì— ë”°ë¼ selected_tool.invoke(tool_call["args"])ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì—¬ê¸°ì„œëŠ” ë¡œì§ ë³€ê²½ ì—†ì´ ì£¼ì„ìœ¼ë¡œë§Œ ì•ˆë‚´)

íƒ€ì„ì¡´ ë¬¸ìì—´: ì˜ˆ) "Asia/Seoul", "America/New_York"ì²˜ëŸ¼ IANA íƒ€ì„ì¡´ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ëª»ëœ ë¬¸ìì—´ì´ë©´ "ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì„ì¡´" ë©”ì‹œì§€ê°€ ë°˜í™˜ë©ë‹ˆë‹¤.

ìŠ¤íŠ¸ë¦¬ë° ì˜ˆì™¸ ì²˜ë¦¬: ë„¤íŠ¸ì›Œí¬/ì¿¼í„° ì—ëŸ¬ ì‹œ UIê°€ ë©ˆì¶œ ìˆ˜ ìˆìœ¼ë‹ˆ, ì‹¤ë¬´ì—ì„œëŠ” try/exceptë¡œ get_ai_response() ë‚´ë¶€ë¥¼ ê°ì‹¸ê³  ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ st.error()ë¡œ ë³´ì—¬ì£¼ë©´ UXê°€ ì¢‹ì•„ì§‘ë‹ˆë‹¤.

í•„ìš”í•˜ë©´ íˆ´ í˜¸ì¶œ ì¸ì êµ¬ì¡°ì— ë§ì¶° í•œ ì¤„ë§Œ ë°”ê¾¸ëŠ” ë²„ì „ë„ ë§Œë“¤ì–´ ë“œë¦´ê²Œìš”. """





