import streamlit as st

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage



#openai_api_keyê°€ì ¸ì˜¤ê¸°
from openai import OpenAI  # ì£¼ì„ì²˜ë¦¬
from dotenv import load_dotenv
import os
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
#openai_api_keyê°€ì ¸ì˜¤ê¸°


# ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o-mini")
# llm = ChatOpenAI(model="gpt-4o-mini", api_key=api_key)
# ì‚¬ìš©ìì˜ ë©”ì‹œì§€ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜
def get_ai_response(messages):
    response = llm.stream(messages)

    for chunk in response:
        yield chunk

# Streamlit ì•±
st.title("ğŸ’¬ langchain_streamlit_tool_0.py")
print("")
st.title("GPT-4o Langchain Chat")

# ìŠ¤íŠ¸ë¦¼ë¦¿ session_stateì— ë©”ì‹œì§€ ì €ì¥
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë•ê¸° ìœ„í•´ ìµœì„ ì„ ë‹¤í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë´‡ì´ë‹¤. "),  
        AIMessage("How can I help you?")
    ]

# ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ì— ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    if msg.content:
        if isinstance(msg, SystemMessage):
            st.chat_message("system").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input():
    st.chat_message("user").write(prompt) # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    st.session_state.messages.append(HumanMessage(prompt)) # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥

    response = get_ai_response(st.session_state["messages"])
    
    result = st.chat_message("assistant").write_stream(response) # AI ë©”ì‹œì§€ ì¶œë ¥
    st.session_state["messages"].append(AIMessage(result)) # AI ë©”ì‹œì§€ ì €ì¥    
